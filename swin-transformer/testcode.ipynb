{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト用のNoote book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToPatches(nn.Module):\n",
    "    \"\"\"1枚の画像を小さなパッチに分割する\n",
    "\n",
    "    Attributes:\n",
    "        patch_size: パッチ1辺のサイズ(2)\n",
    "        projection: パッチデータを線形変換する全結合層\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, dim, patch_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels(int): 入力画像のチャネル数(in_channels=3)\n",
    "            dim(int): 線形変換後のパッチデータの次元(dim=128)\n",
    "            patch_size(int): パッチ1辺のサイズ(patch_size=2)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        # チャネル数にパッチ1辺のサイズの2乗を掛けてパッチ1個のサイズを計算\n",
    "        # 3 * 2 * 2 = 12\n",
    "        patch_dim = in_channels * patch_size * patch_size\n",
    "        # 入力サイズをパッチのサイズ(12)\n",
    "        # ユニット数をdim(128)に設定した全結合層を作成\n",
    "        self.projection = nn.Linear(patch_dim, dim)\n",
    "        # 正規化を行う\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"パッチに分割する一連の順伝播処理\n",
    "        Args:\n",
    "            x(torch.Tensor): 入力画像\n",
    "        Returns:\n",
    "            torch.Tensor: パッチに分割されたテンソル\n",
    "        \"\"\"\n",
    "        # xの形状: (バッチサイズ(bs), チャネル数(3), 画像の高さ(32), 画像の幅(32))\n",
    "        # F.unfoldでパッチに分割\n",
    "        # kernel_size: パッチ1辺のサイズ(2)\n",
    "        # stride: パッチ1辺のサイズ(2)\n",
    "        # F.unfoldの出力の形状: (パッチのサイズ(2*2*3), パッチ数(256),バッチサイズ(bs))\n",
    "        # movedim(1, -1)でバッチサイズとパッチ数を入れ替え\n",
    "        # (バッチサイズ(bs), パッチ数(256), パッチのサイズ(2*2*3))となる\n",
    "        x = F.unfold(x, kernel_size=self.patch_size, stride=self.patch_size).movedim(1, -1)\n",
    "        # パッチデータを線形変換\n",
    "        # 出力の形状: (バッチサイズ(bs), パッチ数(256), パッチのサイズ(128))\n",
    "        x = self.projection(x)\n",
    "        # 正規化を行う\n",
    "        x = self.norm(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topatches = ToPatches(3, 128, 2)\n",
    "x = torch.randn(8, 3, 32, 32)\n",
    "out = topatches(x)\n",
    "# [32, 256, 128]\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_windows(x, window_size):\n",
    "    \"\"\"window_sizeに基づいてバッチテンソルxをウィンドウに分割\n",
    "\n",
    "    Args:\n",
    "        x: バッチテンソル(bs, パッチ数(行), パッチ数(列), パッチサイズ)\n",
    "        window_size: ウィンドウ1辺のサイズ(window_size=4)\n",
    "    Returns:\n",
    "        ウィンドウに分割されたテンソル\n",
    "        (bs * ウィンドウの数, ウィンドウ内のパッチ数(window_size**2), パッチサイズ)\n",
    "    \"\"\" \n",
    "    # 行方向のウィンドウ数n_hと列方向のウィンドウ数n_wを計算\n",
    "    n_h, n_w = x.size(1) // window_size, x.size(2) // window_size\n",
    "    # パッチ行列をウィドウに分割する\n",
    "    # x.unflatten(1, (n_h, window_size))で[bs, パッチ数(行),\\\n",
    "    # パッチ数(列), パッチサイズ ]が\n",
    "    # [bs,ウィドウ数(行), ウィドウサイズ(行), パッチ数, パッチサイズ]に変換される\n",
    "    # .unflatten(-2, (n_w, window_size))で\n",
    "    # [bs,ウィドウ数(行), ウィドウサイズ(行), パッチ数, パッチサイズ]が\n",
    "    # [bs, ウィドウ数(行), ウィドウサイズ(行),\\\n",
    "    #  ウィドウ数(列), ウィドウサイズ(列), パッチサイズ]に変換される \n",
    "    x = x.unflatten(1, (n_h, window_size)).unflatten(-2, (n_w, window_size))\n",
    "    # 第3次元(window_size)と第4次元(ウィドウ数(列))を入れ替えて\n",
    "    # 第一次元、第二次元、第三次元をフラット化\n",
    "    # x.transpose(2, 3)で[bs, ウィドウ数(行), ウィドウサイズ(行),ウィドウ数(列), ウィドウサイズ(列), パッチサイズ]が\n",
    "    # [bs, ウィドウ数(行), ウィンドウ数(列), ウィドウサイズ(行), ウィドウサイズ(列), パッチサイズ]に変換される\n",
    "    # .flatten(0, 2)で[bs, ウィドウ数(行), ウィンドウ数(列), ウィドウサイズ(行), ウィドウサイズ(列), パッチサイズ]が\n",
    "    # [bs * ウィンドウの数(行 * 列), ウィドウサイズ(行), ウィドウサイズ(列), パッチサイズ]に変換される\n",
    "    x = x.transpose(2, 3).flatten(0, 2)\n",
    "    # [bs * ウィンドウの数(行 * 列), ウィドウサイズ(行), ウィドウサイズ(列), パッチサイズ]が\n",
    "    # [bs * ウィンドウの数(行 * 列), ウィドウ内パッチ数, パッチサイズ]\n",
    "    x = x.flatten(-3, -2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 16, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 4\n",
    "\n",
    "x = torch.randn(32, 16, 16, 2)\n",
    "# 返り値 : [32*16=512, 16, 2]\n",
    "x = split_windows(x, window_size)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
